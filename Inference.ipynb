{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWMHvT4xo1gBCuUmynsTlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushmanlohani/Neural-translator-eng-fr-/blob/main/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_XNWqdH65VQ"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. YOUR EXACT MODEL ARCHITECTURE\n",
        "# (Extracted directly from your notebook)\n",
        "# ==========================================\n",
        "\n",
        "class TransformerConfig:\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        block_size=128,\n",
        "        n_layer=6,\n",
        "        n_pre_cross_layer=3,\n",
        "        n_cross_layer=3,\n",
        "        n_embd=256,\n",
        "        num_heads=8,\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.block_size = block_size\n",
        "        self.n_layer = n_layer\n",
        "        self.n_pre_cross_layer = n_pre_cross_layer\n",
        "        self.n_cross_layer = n_cross_layer\n",
        "        self.n_embd = n_embd\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.num_heads == 0\n",
        "        self.num_heads = config.num_heads\n",
        "        self.head_size = config.n_embd // config.num_heads\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "        self.q_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.k_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.v_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.out_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, q, k=None, v=None, mask=None, is_causal=False):\n",
        "        batch_size = q.size(0)\n",
        "        if k is None: k = q\n",
        "        if v is None: v = q\n",
        "\n",
        "        q_out = self.q_proj(q)\n",
        "        k_out = self.k_proj(k)\n",
        "        v_out = self.v_proj(v)\n",
        "\n",
        "        q_out = q_out.view(batch_size, -1, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        k_out = k_out.view(batch_size, -1, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        v_out = v_out.view(batch_size, -1, self.num_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "        scores = (q_out @ k_out.transpose(-2, -1)) / math.sqrt(self.head_size)\n",
        "\n",
        "        if is_causal:\n",
        "            seq_len = q_out.size(-2)\n",
        "            causal_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool, device=q.device), diagonal=1)\n",
        "            scores.masked_fill_(causal_mask, float('-inf'))\n",
        "\n",
        "        if mask is not None:\n",
        "            if mask.dim() == 3: mask = mask.unsqueeze(1)\n",
        "            scores.masked_fill_(~mask, float('-inf'))\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        out = attn @ v_out\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.n_embd)\n",
        "        out = self.out_proj(out)\n",
        "        return out\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.ffwd = FeedForward(config)\n",
        "\n",
        "    def forward(self, x, mask=None, is_causal=False):\n",
        "        x = x + self.attn(self.ln1(x), mask=mask, is_causal=is_causal)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class CrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.self_attn = MultiHeadAttention(config)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.cross_attn = MultiHeadAttention(config)\n",
        "        self.ln3 = nn.LayerNorm(config.n_embd)\n",
        "        self.ffwd = FeedForward(config)\n",
        "\n",
        "    def forward(self, x, enc_out, self_mask=None, cross_mask=None):\n",
        "        x = x + self.self_attn(self.ln1(x), mask=self_mask, is_causal=True)\n",
        "        x = x + self.cross_attn(q=self.ln2(x), k=enc_out, v=enc_out, mask=cross_mask)\n",
        "        x = x + self.ffwd(self.ln3(x))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for block in self.blocks:\n",
        "            x = block(x, mask=mask)\n",
        "        return self.ln_f(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.pre_blocks = nn.ModuleList([Block(config) for _ in range(config.n_pre_cross_layer)])\n",
        "        self.cross_blocks = nn.ModuleList([CrossAttentionBlock(config) for _ in range(config.n_cross_layer)])\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, enc_out, padding_mask=None, cross_mask=None):\n",
        "        for block in self.pre_blocks:\n",
        "            x = block(x, mask=padding_mask, is_causal=True)\n",
        "        for block in self.cross_blocks:\n",
        "            x = block(x, enc_out, self_mask=padding_mask, cross_mask=cross_mask)\n",
        "        return self.ln_f(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.src_tok_emb = nn.Embedding(config.src_vocab_size, config.n_embd)\n",
        "        self.tgt_tok_emb = nn.Embedding(config.tgt_vocab_size, config.n_embd)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.drop = nn.Dropout(config.dropout)\n",
        "        self.encoder = Encoder(config)\n",
        "        self.decoder = Decoder(config)\n",
        "        self.head = nn.Linear(config.n_embd, config.tgt_vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, src_ids, tgt_ids, src_mask=None, tgt_mask=None):\n",
        "        B, T_src = src_ids.size()\n",
        "        _, T_tgt = tgt_ids.size()\n",
        "        src_emb = self.src_tok_emb(src_ids)\n",
        "        src_pos = self.pos_emb[:, :T_src, :]\n",
        "        x = self.drop(src_emb + src_pos)\n",
        "        encoder_out = self.encoder(x, src_mask)\n",
        "        tgt_emb = self.tgt_tok_emb(tgt_ids)\n",
        "        tgt_pos = self.pos_emb[:, :T_tgt, :]\n",
        "        y = self.drop(tgt_emb + tgt_pos)\n",
        "        y = self.decoder(y, encoder_out, padding_mask=tgt_mask, cross_mask=src_mask)\n",
        "        logits = self.head(y)\n",
        "        return logits\n",
        "\n",
        "# ==========================================\n",
        "# 2. HELPER FUNCTIONS & LOADING\n",
        "# ==========================================\n",
        "\n",
        "def basic_tokenize(text):\n",
        "    \"\"\"Exact tokenizer from your notebook\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'([.,!?;])', r' \\1 ', text)\n",
        "    text = re.sub(r'([\\\"\\'])', r' \\1 ', text)\n",
        "    text = re.sub(r'[^a-z0-9.,!?;\\'\\\" ]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text.split()\n",
        "\n",
        "def load_vocab(file_path):\n",
        "    vocab = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                vocab[parts[0]] = int(parts[1])\n",
        "    return vocab\n",
        "\n",
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, device, max_length=50):\n",
        "    model.eval()\n",
        "    tokens = basic_tokenize(sentence)\n",
        "\n",
        "    # Mapping based on your notebook\n",
        "    # <pad>:0, <unk>:1, <sos>:2, <eos>:3\n",
        "    src_indices = [src_vocab.get('<sos>', 2)] + \\\n",
        "                  [src_vocab.get(t, src_vocab.get('<unk>', 1)) for t in tokens] + \\\n",
        "                  [src_vocab.get('<eos>', 3)]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(device)\n",
        "    src_mask = (src_tensor != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_emb = model.src_tok_emb(src_tensor)\n",
        "        src_pos = model.pos_emb[:, :src_tensor.size(1), :]\n",
        "        encoder_out = model.encoder(model.drop(src_emb + src_pos), src_mask)\n",
        "\n",
        "    tgt_indices = [tgt_vocab.get('<sos>', 2)]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        tgt_tensor = torch.LongTensor(tgt_indices).unsqueeze(0).to(device)\n",
        "        tgt_mask = (tgt_tensor != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tgt_emb = model.tgt_tok_emb(tgt_tensor)\n",
        "            tgt_pos = model.pos_emb[:, :tgt_tensor.size(1), :]\n",
        "            y = model.drop(tgt_emb + tgt_pos)\n",
        "\n",
        "            output = model.decoder(y, encoder_out, padding_mask=tgt_mask, cross_mask=src_mask)\n",
        "            logits = model.head(output)\n",
        "            next_token_id = logits[0, -1, :].argmax().item()\n",
        "\n",
        "            tgt_indices.append(next_token_id)\n",
        "            if next_token_id == tgt_vocab.get('<eos>', 3):\n",
        "                break\n",
        "\n",
        "    idx_to_word = {v: k for k, v in tgt_vocab.items()}\n",
        "    translated_tokens = []\n",
        "    for idx in tgt_indices:\n",
        "        token = idx_to_word.get(idx, '')\n",
        "        if token not in ['<sos>', '<eos>', '<pad>']:\n",
        "            translated_tokens.append(token)\n",
        "\n",
        "    return \" \".join(translated_tokens)\n",
        "\n",
        "# ==========================================\n",
        "# 3. STREAMLIT APP\n",
        "# ==========================================\n",
        "\n",
        "st.set_page_config(page_title=\"Eng-Fr Translator\", layout=\"centered\")\n",
        "\n",
        "st.title(\"ðŸ‡«ðŸ‡· English to French Translator\")\n",
        "st.write(\"Using a custom trained Transformer model.\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load Vocabs\n",
        "    eng_vocab = load_vocab('eng_vocab.txt')\n",
        "    fr_vocab = load_vocab('fr_vocab.txt')\n",
        "\n",
        "    # Initialize Configuration (Using your EXACT notebook params)\n",
        "    config = TransformerConfig(\n",
        "        src_vocab_size=len(eng_vocab),\n",
        "        tgt_vocab_size=len(fr_vocab),\n",
        "        block_size=128,\n",
        "        n_layer=6,\n",
        "        n_pre_cross_layer=3,\n",
        "        n_cross_layer=3,\n",
        "        n_embd=256,\n",
        "        num_heads=8,\n",
        "        dropout=0.1\n",
        "    )\n",
        "\n",
        "    # Load Model\n",
        "    model = Transformer(config).to(device)\n",
        "    # Load State Dict\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('best_model.pt', map_location=device))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load weights: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    return model, eng_vocab, fr_vocab, device\n",
        "\n",
        "model, eng_vocab, fr_vocab, device = load_resources()\n",
        "\n",
        "if model:\n",
        "    user_input = st.text_area(\"Enter English text:\", height=100)\n",
        "\n",
        "    if st.button(\"Translate\"):\n",
        "        if user_input:\n",
        "            with st.spinner(\"Translating...\"):\n",
        "                translation = translate_sentence(model, user_input, eng_vocab, fr_vocab, device)\n",
        "                st.success(\"French Translation:\")\n",
        "                st.info(translation)\n",
        "        else:\n",
        "            st.warning(\"Please enter some text.\")"
      ],
      "metadata": {
        "id": "drBlTTPn8kz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Fetch the token securely\n",
        "ngrok_token = userdata.get('NGROK_TOKEN')\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Terminate open tunnels if any exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Run Streamlit in background\n",
        "!streamlit run app.py &>/dev/null&\n",
        "\n",
        "# Open the tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(8501).public_url\n",
        "    print(f\"ðŸš€ Click here to use your app: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting tunnel: {e}\")"
      ],
      "metadata": {
        "id": "hF7cRrxl8mkj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}